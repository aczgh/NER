{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "convert_Data_Into_Raw_Text.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#### Pulling the data from Github\n",
        "\n",
        "The dataset, includes train, test and dev sets, which we pull from the [Github repository](https://github.com/shreyashub/BioFLAIR/tree/master/data/ner/BC5CDR-disease)."
      ],
      "metadata": {
        "id": "akp3YQ46uV6m"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YQDZpEk-t7RT"
      },
      "outputs": [],
      "source": [
        "## download data from githup \n",
        "\n",
        "import urllib.request\n",
        "from pathlib import Path\n",
        "\n",
        "def download_file(url, output_file):\n",
        "  Path(output_file).parent.mkdir(parents=True, exist_ok=True)\n",
        "  urllib.request.urlretrieve (url, output_file)\n",
        "\n",
        "download_file('https://raw.githubusercontent.com/shreyashub/BioFLAIR/master/data/ner/bc5cdr/train.txt', '/content/data/train.txt')\n",
        "download_file('https://raw.githubusercontent.com/shreyashub/BioFLAIR/master/data/ner/bc5cdr/test.txt', '/content/data/test.txt')\n",
        "download_file('https://raw.githubusercontent.com/shreyashub/BioFLAIR/master/data/ner/bc5cdr/dev.txt', '/content/data/dev.txt')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ## get data from githup \n",
        "# !wget https://github.com/shreyashub/BioFLAIR/blob/master/data/ner/BC5CDR-disease/train.tsv \n",
        "# !wget https://github.com/shreyashub/BioFLAIR/blob/master/data/ner/BC5CDR-disease/test.tsv\n",
        "# !wget https://github.com/shreyashub/BioFLAIR/blob/master/data/ner/BC5CDR-disease/devel.tsv\n",
        "# !wget https://github.com/shreyashub/BioFLAIR/blob/master/data/ner/BC5CDR-disease/train_dev.tsv\n",
        "\n"
      ],
      "metadata": {
        "id": "frY6rDPlwJZC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Since the data is formatted in the CoNLL BIO type format (you can read more on the tagging format from this wikipedia article), we need to format it into a pandas dataframe with the following function. The 2 important columns in the dataframe are a word token (for mandarin this is a single character), a BIO label and a sentence_id to differentiate samples/sentences.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "orJo-bPGxmVf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## read tsv file \n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "def read_conll(filename):\n",
        "    df = pd.read_csv(filename,\n",
        "                    sep = '\\t', header = None, keep_default_na = False,\n",
        "                    names = ['words', 'pos', 'chunk', 'labels'],\n",
        "                    quoting = 3, skip_blank_lines = False)\n",
        "    df = df[~df['words'].astype(str).str.startswith('-DOCSTART- ')] # Remove the -DOCSTART- header\n",
        "    # df['sentence_id'] = (df.words == '').cumsum()\n",
        "    return df[df.words != '']"
      ],
      "metadata": {
        "id": "ef-dvn4FxZMt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## read text ata as dataframe \n",
        "train_df = read_conll('/content/data/train.txt')\n",
        "test_df = read_conll('/content/data/test.txt')\n",
        "dev_df = read_conll('/content/data/dev.txt')\n",
        "train_df.head(10)"
      ],
      "metadata": {
        "id": "hf41zvQb0esY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.head(3)"
      ],
      "metadata": {
        "id": "KWHgSEya2WRK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dev_df.head(3)"
      ],
      "metadata": {
        "id": "bRktL8n50oMX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## concat all dataframe with other \n",
        "df = pd.concat([train_df, test_df , dev_df] )\n",
        "df.head(3)"
      ],
      "metadata": {
        "id": "2HVzx6HT1ahW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(4)"
      ],
      "metadata": {
        "id": "110sbWVw2wt2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## shape of full dataset \n",
        "df.shape"
      ],
      "metadata": {
        "id": "xAEy26rT20Ra"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## count chunk\n",
        "df['chunk'].value_counts()"
      ],
      "metadata": {
        "id": "g-LHxfZm4q-u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## count all speech tagging in labels \n",
        "df['labels'].value_counts()"
      ],
      "metadata": {
        "id": "n4AhWV4K24KN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## This is All Text Tagging \n",
        "\n",
        "* NOUN    \n",
        "* PUNCT    \n",
        "* ADP     \n",
        "* VERB   \n",
        "* ADJ      \n",
        "* DET      \n",
        "* PROPN    \n",
        "* NUM      \n",
        "* CCONJ    \n",
        "* ADV       \n",
        "* SYM       \n",
        "* PART      \n",
        "* PRON      \n",
        "* X          \n",
        "* INTJ        "
      ],
      "metadata": {
        "id": "I9zMZRVA3ZhO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## create dictionary from tagging for word in dataset\n",
        "df['pos'].value_counts()"
      ],
      "metadata": {
        "id": "mB0JvIE92-jO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## create dictionary of word and pos for each word \n",
        "AllWords = list(df['words'].values)\n",
        "Allpos = list(df['pos'].values)\n",
        "AllLabels = list(df['labels'].values)\n"
      ],
      "metadata": {
        "id": "jiiSE6_i3VNz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## create dictionary \n",
        "wordsPos = []\n",
        "wordsLabels = []\n",
        "for i in range(len(AllWords)):\n",
        "    wordsPos.append({\"word\" : AllWords[i] , \"pos\" : Allpos[i] })\n",
        "    wordsLabels.append({\"word\" : AllWords[i] , \"label\" : AllLabels[i] })"
      ],
      "metadata": {
        "id": "dHF2BcGO5Ymu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wordsLabels[:3]"
      ],
      "metadata": {
        "id": "a5B9_6Q15bgW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## save list of pos\n",
        "pos = pd.DataFrame(wordsPos) \n",
        "print(pos.head(3)) "
      ],
      "metadata": {
        "id": "tHgWYYJj6CyM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## save list of labels as dataframe \n",
        "labels = pd.DataFrame(wordsLabels) \n",
        "print(labels.head(3)) "
      ],
      "metadata": {
        "id": "hZynoUfD8SLR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## save list of pos and labels entity \n",
        "labels.to_csv(\"Entity_labels.csv\" , index=False)\n",
        "pos.to_csv(\"pos.csv\" , index=False)"
      ],
      "metadata": {
        "id": "i6ErQNII8gkW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## list columns \n",
        "df.columns"
      ],
      "metadata": {
        "id": "hjURxksK9xpd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_text =  ' '.join(AllWords)"
      ],
      "metadata": {
        "id": "oI6--hTP-SjK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## save data into text\n",
        "with open('BC5CDR_DATA.txt', 'w') as f:\n",
        "    f.write(raw_text)"
      ],
      "metadata": {
        "id": "bdi8ybVc-yux"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "QyvhTbLU-0kU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}